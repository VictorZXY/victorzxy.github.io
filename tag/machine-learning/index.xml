<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning | Xiangyu Zhao</title>
    <link>https://victorzxy.github.io/tag/machine-learning/</link>
      <atom:link href="https://victorzxy.github.io/tag/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2022 Xiangyu Zhao</copyright><lastBuildDate>Wed, 24 Aug 2022 18:50:00 +0000</lastBuildDate>
    <image>
      <url>https://victorzxy.github.io/media/icon_hu445124fc86f9a5e0ef5204885c05fa2c_2309_512x512_fill_lanczos_center_3.png</url>
      <title>Machine Learning</title>
      <link>https://victorzxy.github.io/tag/machine-learning/</link>
    </image>
    
    <item>
      <title>Towards a Competitive 3-Player Mahjong AI using Deep Reinforcement Learning</title>
      <link>https://victorzxy.github.io/talk/towards-a-competitive-3-player-mahjong-ai-using-deep-reinforcement-learning/</link>
      <pubDate>Wed, 24 Aug 2022 18:50:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/talk/towards-a-competitive-3-player-mahjong-ai-using-deep-reinforcement-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration</title>
      <link>https://victorzxy.github.io/talk/task-agnostic-graph-neural-network-evaluation-via-adversarial-collaboration/</link>
      <pubDate>Wed, 08 Jun 2022 09:10:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/talk/task-agnostic-graph-neural-network-evaluation-via-adversarial-collaboration/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration</title>
      <link>https://victorzxy.github.io/post/graphac/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/graphac/</guid>
      <description>&lt;p&gt;Graph Neural Networks (GNNs) have experienced rapid growth over the last decade, and have been successful in many real-world applications. In order to cope with the rapid growth of this field, it is increasingly demanding to develop reliable GNN evaluation methods to facilitate GNN research and quantify their progress. Current GNN benchmarking methods all focus on comparing the GNNs with respect to their training performances on some node/graph classification/regression tasks in certain datasets, but there has not been any principled, task-agnostic method to directly compare the two GNNs.&lt;/p&gt;
&lt;p&gt;Furthermore, learning informative representations of graph-structured data using self-supervised learning (SSL) is becoming crucial in many real-world tasks nowadays, when labelled data are expensive and limited. Most of the existing graph SSL works incorporate handcrafted augmentations to the graph, which has several severe difficulties due to the unique characteristics of graph-structured data. Therefore, it is highly needed to develop a principled SSL framework across various types of graphs, that does not require handcrafted augmentations.&lt;/p&gt;
&lt;p&gt;In this project, I tackled both questions above, and developed GraphAC (Graph Adversarial Collaboration), a conceptually novel, principled, task-agnostic, and stable framework for evaluating GNNs through contrastive self-supervision. It consists of two different GNNs directly competing against each other, with the more expressive GNN wins by producing more informative graph representations. I built two frameworks for GraphAC, and designed a novel objective function that enables stable and effective training of two different GNNs, inspired by Barlow Twins.&lt;/p&gt;
&lt;p&gt;The experimental results show that GraphAC succeeds in distinguishing GNNs of different expressivity across various aspects including the number of layers, hidden dimensionality, aggregators, GNN architecture and edge features, and always allow more expressive GNNs to win with statistically significant difference. GraphAC proved to be a principled and reliable GNN evaluation method, and enables stable SSL without needing handcrafted augmentations.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration</title>
      <link>https://victorzxy.github.io/project/graphac/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/graphac/</guid>
      <description>&lt;p&gt;Graph Neural Networks (GNNs) have experienced rapid growth over the last decade, and have been successful in many real-world applications. In order to cope with the rapid growth of this field, it is increasingly demanding to develop reliable GNN evaluation methods to facilitate GNN research and quantify their progress. Current GNN benchmarking methods all focus on comparing the GNNs with respect to their training performances on some node/graph classification/regression tasks in certain datasets, but there has not been any principled, task-agnostic method to directly compare the two GNNs.&lt;/p&gt;
&lt;p&gt;Furthermore, learning informative representations of graph-structured data using self-supervised learning (SSL) is becoming crucial in many real-world tasks nowadays, when labelled data are expensive and limited. Most of the existing graph SSL works incorporate handcrafted augmentations to the graph, which has several severe difficulties due to the unique characteristics of graph-structured data. Therefore, it is highly needed to develop a principled SSL framework across various types of graphs, that does not require handcrafted augmentations.&lt;/p&gt;
&lt;p&gt;In this project, I tackled both questions above, and developed GraphAC (Graph Adversarial Collaboration), a conceptually novel, principled, task-agnostic, and stable framework for evaluating GNNs through contrastive self-supervision. It consists of two different GNNs directly competing against each other, with the more expressive GNN wins by producing more informative graph representations. I built two frameworks for GraphAC, and designed a novel objective function that enables stable and effective training of two different GNNs, inspired by Barlow Twins.&lt;/p&gt;
&lt;p&gt;The experimental results show that GraphAC succeeds in distinguishing GNNs of different expressivity across various aspects including the number of layers, hidden dimensionality, aggregators, GNN architecture and edge features, and always allow more expressive GNNs to win with statistically significant difference. GraphAC proved to be a principled and reliable GNN evaluation method, and enables stable SSL without needing handcrafted augmentations.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards a Competitive 3-Player Mahjong AI using Deep Reinforcement Learning</title>
      <link>https://victorzxy.github.io/publication/2022-meowjong-auxiliary/</link>
      <pubDate>Fri, 13 May 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/publication/2022-meowjong-auxiliary/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Improving Graph Generative Models via Expressive Graph Neural Networks</title>
      <link>https://victorzxy.github.io/post/expressive-graph-gen/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/expressive-graph-gen/</guid>
      <description>&lt;p&gt;Graph generation is a very challenging problem that requires predicting an entire graph with multiple nodes and edges from a given label, and is fundamental for many real-world tasks, such as molecular graph generation for drug discovery. A lot of successful methods have been explored on graph generation, including Graph Convolutional Policy Network (GCPN) and GraphAF, but the underlying graph neural network (GNN) structure for graph representation within both works remains untouched, namely the Relational Graph Convolutional Network (R-GCN). In this project, we investigate the expressivity of GNNs under the context of the graph generation problem, by replacing R-GCN in GCPN with more expressive GNNs, including Graph Isomorphism Network (GIN), Principal Neighbourhood Aggregation (PNA) and Graph Substructure Network (GSN). Experimental results show that more expressive GNNs can indeed significantly improve GCPN&amp;rsquo;s performance on chemical property optimisation, with the only bottleneck coming from the sensitive nature of the graph generative method. In addition, since nearly all of the recent works on new GNN architectures are focused on pushing node/graph classification/regression benchmarks, which are comparatively simpler than graph generation modelling in terms of the combinatorial complexity, we also wish to challenge the graph representation learning community&amp;rsquo;s notion for benchmarking the expressivity of GNNs with this project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Graph Generative Models via Expressive Graph Neural Networks</title>
      <link>https://victorzxy.github.io/project/expressive-graph-gen/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/expressive-graph-gen/</guid>
      <description>&lt;p&gt;Graph generation is a very challenging problem that requires predicting an entire graph with multiple nodes and edges from a given label, and is fundamental for many real-world tasks, such as molecular graph generation for drug discovery. A lot of successful methods have been explored on graph generation, including Graph Convolutional Policy Network (GCPN) and GraphAF, but the underlying graph neural network (GNN) structure for graph representation within both works remains untouched, namely the Relational Graph Convolutional Network (R-GCN). In this project, we investigate the expressivity of GNNs under the context of the graph generation problem, by replacing R-GCN in GCPN with more expressive GNNs, including Graph Isomorphism Network (GIN), Principal Neighbourhood Aggregation (PNA) and Graph Substructure Network (GSN). Experimental results show that more expressive GNNs can indeed significantly improve GCPN&amp;rsquo;s performance on chemical property optimisation, with the only bottleneck coming from the sensitive nature of the graph generative method. In addition, since nearly all of the recent works on new GNN architectures are focused on pushing node/graph classification/regression benchmarks, which are comparatively simpler than graph generation modelling in terms of the combinatorial complexity, we also wish to challenge the graph representation learning community&amp;rsquo;s notion for benchmarking the expressivity of GNNs with this project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Agent Deep Q-Learning for the Berry Poisoning Game</title>
      <link>https://victorzxy.github.io/post/dqn-berry-poisoning/</link>
      <pubDate>Thu, 17 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/dqn-berry-poisoning/</guid>
      <description>&lt;p&gt;Deep Q-learning (DQN) is a successful algorithm that combines deep learning with reinforcement learning. However, it is of great research interest whether this method can work in a multi-agent environment. In this mini-project, I performed a multi-agent DQN method on the Berry Poisoning Games, and investigated on the agent performance with respect to different game environment parameters, including the bad berry rate, bad/good berry reward ratio, number of agents, and agent visibility range. The results clearly show that my DQN method can successfully train agents to act sensibly in such an environment, within only a few episodes of training. My DQN method also succeeds in transfer learning, training agents that still perform well in other game environment setups, and can be further enhanced through fine-tuning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Agent Deep Q-Learning for the Berry Poisoning Game</title>
      <link>https://victorzxy.github.io/project/dqn-berry-poisoning/</link>
      <pubDate>Thu, 17 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/dqn-berry-poisoning/</guid>
      <description>&lt;p&gt;Deep Q-learning (DQN) is a successful algorithm that combines deep learning with reinforcement learning. However, it is of great research interest whether this method can work in a multi-agent environment. In this mini-project, I performed a multi-agent DQN method on the Berry Poisoning Games, and investigated on the agent performance with respect to different game environment parameters, including the bad berry rate, bad/good berry reward ratio, number of agents, and agent visibility range. The results clearly show that my DQN method can successfully train agents to act sensibly in such an environment, within only a few episodes of training. My DQN method also succeeds in transfer learning, training agents that still perform well in other game environment setups, and can be further enhanced through fine-tuning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a 3-Player Mahjong AI using Deep Reinforcement Learning</title>
      <link>https://victorzxy.github.io/publication/2022-meowjong/</link>
      <pubDate>Fri, 25 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/publication/2022-meowjong/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Asynchronous Methods for Deep Reinforcement Learning</title>
      <link>https://victorzxy.github.io/talk/asynchronous-methods-for-deep-reinforcement-learning/</link>
      <pubDate>Fri, 11 Feb 2022 15:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/talk/asynchronous-methods-for-deep-reinforcement-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Building a Simulator and Emulator for Traffic Signalling</title>
      <link>https://victorzxy.github.io/talk/building-a-simulator-and-emulator-for-traffic-signalling/</link>
      <pubDate>Mon, 07 Feb 2022 14:30:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/talk/building-a-simulator-and-emulator-for-traffic-signalling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Function Autoencoders: A Neural Network Approach to Gaussian Processes</title>
      <link>https://victorzxy.github.io/post/function-autoencoders/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/function-autoencoders/</guid>
      <description>&lt;p&gt;Gaussian processes (GPs) are data-efficient and flexible probabilistic methods that learn distributions of functions based on given priors. However, GPs suffer from unscalability as they become very computationally expensive on large datasets, and choosing the appropriate priors for GPs can be nontrivial. In this project, I investigated a neural network (NN) alternative to GPs, and introduced the function autoencoders that preserve GPs’ own advantages and avoid their weaknesses with NNs’ benefits. I tested the performance of the various function autoencoders on a 1-dimensional function regression task, using random functions generated by a GP with varying kernel parameters, and compared and analysed their results. The trained function autoencoder models indeed have the ability to learn distributions over random functions, and performed decently on the selected task. Moreover, the function autoencoders demonstrate a great potential for further improvements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Function Autoencoders: A Neural Network Approach to Gaussian Processes</title>
      <link>https://victorzxy.github.io/project/function-autoencoders/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/function-autoencoders/</guid>
      <description>&lt;p&gt;Gaussian processes (GPs) are data-efficient and flexible probabilistic methods that learn distributions of functions based on given priors. However, GPs suffer from unscalability as they become very computationally expensive on large datasets, and choosing the appropriate priors for GPs can be nontrivial. In this project, I investigated a neural network (NN) alternative to GPs, and introduced the function autoencoders that preserve GPs’ own advantages and avoid their weaknesses with NNs’ benefits. I tested the performance of the various function autoencoders on a 1-dimensional function regression task, using random functions generated by a GP with varying kernel parameters, and compared and analysed their results. The trained function autoencoder models indeed have the ability to learn distributions over random functions, and performed decently on the selected task. Moreover, the function autoencoders demonstrate a great potential for further improvements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Simulator and Emulator for Traffic Signalling</title>
      <link>https://victorzxy.github.io/post/traffic-sim/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/traffic-sim/</guid>
      <description>&lt;p&gt;In this project, we carried out simulation and emulation of an urban traffic signalling system. We first built a simulator that can randomly generate networks and car routes to test how different signal scheduling choices affect the total distance travelled by cars in a given period. Based on this, we built an emulator to search for optimal scheduling using Bayesian optimisation. To overcome the problem of exploding search space without sacrificing flexibility or descriptiveness, we introduced four different scheduling schemes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distinct scheduling&lt;/li&gt;
&lt;li&gt;Uniform scheduling&lt;/li&gt;
&lt;li&gt;Preset scheduling&lt;/li&gt;
&lt;li&gt;Forced-preset scheduling&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We then conducted experiments on very small networks (5 junctions), small networks (40 junctions) and medium networks (200 junctions) to compare their performances. Results show that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preset scheduling gives the best convergence limit under reasonable number of iterations in most cases;&lt;/li&gt;
&lt;li&gt;Uniform and distinct scheduling give much poorer performance due to their own limitations;&lt;/li&gt;
&lt;li&gt;Forced-preset scheduling does show certain potential in some cases, but is rather unstable compared to preset scheduling.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We believe that the combination of Bayesian optimisation with traffic planning offers some novel insights and has much more potential to be discovered. With sufficient research effort, this area would bring great benefit to city planners and the general public, with potential applications in other areas that involves network traffic controls.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Simulator and Emulator for Traffic Signalling</title>
      <link>https://victorzxy.github.io/project/traffic-sim/</link>
      <pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/traffic-sim/</guid>
      <description>&lt;p&gt;In this project, we carried out simulation and emulation of an urban traffic signalling system. We first built a simulator that can randomly generate networks and car routes to test how different signal scheduling choices affect the total distance travelled by cars in a given period. Based on this, we built an emulator to search for optimal scheduling using Bayesian optimisation. To overcome the problem of exploding search space without sacrificing flexibility or descriptiveness, we introduced four different scheduling schemes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distinct scheduling&lt;/li&gt;
&lt;li&gt;Uniform scheduling&lt;/li&gt;
&lt;li&gt;Preset scheduling&lt;/li&gt;
&lt;li&gt;Forced-preset scheduling&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We then conducted experiments on very small networks (5 junctions), small networks (40 junctions) and medium networks (200 junctions) to compare their performances. Results show that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preset scheduling gives the best convergence limit under reasonable number of iterations in most cases;&lt;/li&gt;
&lt;li&gt;Uniform and distinct scheduling give much poorer performance due to their own limitations;&lt;/li&gt;
&lt;li&gt;Forced-preset scheduling does show certain potential in some cases, but is rather unstable compared to preset scheduling.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We believe that the combination of Bayesian optimisation with traffic planning offers some novel insights and has much more potential to be discovered. With sufficient research effort, this area would bring great benefit to city planners and the general public, with potential applications in other areas that involves network traffic controls.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Neural Network Approach to Named Entity Recognition on Noisy User-Generated Texts</title>
      <link>https://victorzxy.github.io/post/nlp-final-assignment-ner/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/nlp-final-assignment-ner/</guid>
      <description>&lt;p&gt;Named entity recognition (NER) is an important information extraction task in natural language processing (NLP) which involves automatic identification of entities of interest, such as people&amp;rsquo;s names, organisations and locations. Current state-of-the-art NER systems can achieve F1-scores of up to 94.6% on English news texts (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.206.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021a&lt;/a&gt;), where the named entities are fairly standard, well-formed and highly predictable. However, the diverse and noisy nature of user-generated texts as well as the novel, emerging and rare named entities make NER in social media much more challenging, and standard NER sysmtes were not found to work very well on these tasks. As a comparison, current state-of-the-art NER systems on user-generated texts can only achieve F1-scores of up to 60.45% (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.142.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021b&lt;/a&gt;). In this project, I investigated a bidirectional long short-term memory (BiLSTM) structure for NER on social media texts, explored various data-processing techniques in order to improve the model&amp;rsquo;s performance, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downweighting non-named entity labels&lt;/li&gt;
&lt;li&gt;Downsampling non-named entity tokens&lt;/li&gt;
&lt;li&gt;Merging named entity labels&lt;/li&gt;
&lt;li&gt;Adding part-of-speech (PoS) embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then evaluated my trained models on the W-NUT 2017 shared task on novel and emerging entity recognition. The model trained with data-processing techniques applied has achieved significant improvements on performance, compared to the model with the same structure, but trained on the original dataset without any optimisation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Neural Network Approach to Named Entity Recognition on Noisy User-Generated Texts</title>
      <link>https://victorzxy.github.io/project/nlp-final-assignment-ner/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/nlp-final-assignment-ner/</guid>
      <description>&lt;p&gt;Named entity recognition (NER) is an important information extraction task in natural language processing (NLP) which involves automatic identification of entities of interest, such as people&amp;rsquo;s names, organisations and locations. Current state-of-the-art NER systems can achieve F1-scores of up to 94.6% on English news texts (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.206.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021a&lt;/a&gt;), where the named entities are fairly standard, well-formed and highly predictable. However, the diverse and noisy nature of user-generated texts as well as the novel, emerging and rare named entities make NER in social media much more challenging, and standard NER sysmtes were not found to work very well on these tasks. As a comparison, current state-of-the-art NER systems on user-generated texts can only achieve F1-scores of up to 60.45% (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.142.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021b&lt;/a&gt;). In this project, I investigated a bidirectional long short-term memory (BiLSTM) structure for NER on social media texts, explored various data-processing techniques in order to improve the model&amp;rsquo;s performance, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downweighting non-named entity labels&lt;/li&gt;
&lt;li&gt;Downsampling non-named entity tokens&lt;/li&gt;
&lt;li&gt;Merging named entity labels&lt;/li&gt;
&lt;li&gt;Adding part-of-speech (PoS) embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then evaluated my trained models on the W-NUT 2017 shared task on novel and emerging entity recognition. The model trained with data-processing techniques applied has achieved significant improvements on performance, compared to the model with the same structure, but trained on the original dataset without any optimisation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning for Mahjong</title>
      <link>https://victorzxy.github.io/post/meowjong/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/meowjong/</guid>
      <description>&lt;p&gt;Mahjong is a popular multi-player imperfect-information game developed in China in the late 19th-century, with some very challenging features for AI research. Sanma, being a 3-player variant of the Japanese Riichi Mahjong, possesses unique characteristics including fewer tiles and, consequently, a more aggressive playing style. It is thus challenging and of great research interest in its own right, but has not yet been explored. In this project, I built Meowjong, an AI for Sanma using deep reinforcement learning. I defined an informative and compact 2-dimensional data structure for encoding the observable information in a Sanma game. Then, I pre-trained 5 convolutional neural networks (CNNs) for Sanma&amp;rsquo;s 5 actions—discard, Pon, Kan, Kita and Riichi, and enhanced the major action&amp;rsquo;s model, namely the discard model, via self-play reinforcement learning using the Monte Carlo policy gradient method. I have also implemeted necessary additional modules including data collection and processing, Mahjong hand calculation and a game simulator, for the agents to be trained and evaluated. Meowjong&amp;rsquo;s models have achieved test accuracies comparable with AIs for 4-player Mahjong through supervised learning, and gained a significant further enhancement from reinforcement learning. Being the first ever AI in Sanma, Meowjong stands as a state-of-the-art in this game.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;https://victorzxy.github.io/publication/2022-meowjong-auxiliary&#34;&gt;paper&lt;/a&gt; from this dissertation has been accepted at the 2022 IEEE Conference on Games (CoG).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning for Mahjong</title>
      <link>https://victorzxy.github.io/project/meowjong/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/meowjong/</guid>
      <description>&lt;p&gt;Mahjong is a popular multi-player imperfect-information game developed in China in the late 19th-century, with some very challenging features for AI research. Sanma, being a 3-player variant of the Japanese Riichi Mahjong, possesses unique characteristics including fewer tiles and, consequently, a more aggressive playing style. It is thus challenging and of great research interest in its own right, but has not yet been explored. In this project, I built Meowjong, an AI for Sanma using deep reinforcement learning. I defined an informative and compact 2-dimensional data structure for encoding the observable information in a Sanma game. Then, I pre-trained 5 convolutional neural networks (CNNs) for Sanma&amp;rsquo;s 5 actions—discard, Pon, Kan, Kita and Riichi, and enhanced the major action&amp;rsquo;s model, namely the discard model, via self-play reinforcement learning using the Monte Carlo policy gradient method. I have also implemeted necessary additional modules including data collection and processing, Mahjong hand calculation and a game simulator, for the agents to be trained and evaluated. Meowjong&amp;rsquo;s models have achieved test accuracies comparable with AIs for 4-player Mahjong through supervised learning, and gained a significant further enhancement from reinforcement learning. Being the first ever AI in Sanma, Meowjong stands as a state-of-the-art in this game.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;https://victorzxy.github.io/publication/2022-meowjong-auxiliary&#34;&gt;paper&lt;/a&gt; from this dissertation has been accepted at the 2022 IEEE Conference on Games (CoG).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigating Adversarial Examples for Deep Residual Networks</title>
      <link>https://victorzxy.github.io/post/fgsm-attack-resnets/</link>
      <pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/fgsm-attack-resnets/</guid>
      <description>&lt;p&gt;In this project, I investigated the one-shot and iterative fast gradient sign method (FGSM) attack, both untargeted and targeted, to generate adversarial examples for ResNet-50, and experimented the transferability of each FGSM to other neural networks, namely ResNet-18 and VGG-19, as well as other image inputs. The following conclusions can be reached after the above experiments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Targeted FGSM is more effective than FGSM;&lt;/li&gt;
&lt;li&gt;In white-box attacks, both the untargeted and targeted one-shot FGSMs are less effective than the iterative methods (both untargeted and targeted);&lt;/li&gt;
&lt;li&gt;When it comes to transferability to other neural networks or inputs, the one-shot FGSMs turn out to be much more effective than the iterative FGSMs, as the iterative FGSMs suffer from overfitting and hence completely unable to transfer to other neural networks or inputs.&lt;/li&gt;
&lt;li&gt;Since transferability is a foundation to black-box attacks, it is likely that the one-shot FGSMs can also be more effective than the iterative FGSMs in black-box attacks.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Investigating Adversarial Examples for Deep Residual Networks</title>
      <link>https://victorzxy.github.io/project/fgsm-attack-resnets/</link>
      <pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/fgsm-attack-resnets/</guid>
      <description>&lt;p&gt;In this project, I investigated the one-shot and iterative fast gradient sign method (FGSM) attack, both untargeted and targeted, to generate adversarial examples for ResNet-50, and experimented the transferability of each FGSM to other neural networks, namely ResNet-18 and VGG-19, as well as other image inputs. The following conclusions can be reached after the above experiments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Targeted FGSM is more effective than FGSM;&lt;/li&gt;
&lt;li&gt;In white-box attacks, both the untargeted and targeted one-shot FGSMs are less effective than the iterative methods (both untargeted and targeted);&lt;/li&gt;
&lt;li&gt;When it comes to transferability to other neural networks or inputs, the one-shot FGSMs turn out to be much more effective than the iterative FGSMs, as the iterative FGSMs suffer from overfitting and hence completely unable to transfer to other neural networks or inputs.&lt;/li&gt;
&lt;li&gt;Since transferability is a foundation to black-box attacks, it is likely that the one-shot FGSMs can also be more effective than the iterative FGSMs in black-box attacks.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Analysing Clickstream Data for Online Shopping</title>
      <link>https://victorzxy.github.io/post/datasci-pnp-final-practical/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/datasci-pnp-final-practical/</guid>
      <description>&lt;p&gt;In this project, I analysed a clickstream dataset of an online shopping website for clothing between April and August 2008, and built a machine learning pipeline to predict the costumer’s potential willingness to pay a premium price. I explored, trained and compared various machine learning models for this task, ranging from traditional models to deep neural networks, and identified the most important features for predicting the target value. The best-performing model the I trained for this project has achieved a test accuracy of 93.37%. I also performed visualisation and dimensionality reduction, using PCA and t-SNE, to reveal properties of the dataset and my models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysing Clickstream Data for Online Shopping</title>
      <link>https://victorzxy.github.io/project/datasci-pnp-final-practical/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/datasci-pnp-final-practical/</guid>
      <description>&lt;p&gt;In this project, I analysed a clickstream dataset of an online shopping website for clothing between April and August 2008, and built a machine learning pipeline to predict the costumer’s potential willingness to pay a premium price. I explored, trained and compared various machine learning models for this task, ranging from traditional models to deep neural networks, and identified the most important features for predicting the target value. The best-performing model the I trained for this project has achieved a test accuracy of 93.37%. I also performed visualisation and dimensionality reduction, using PCA and t-SNE, to reveal properties of the dataset and my models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trading Assistant</title>
      <link>https://victorzxy.github.io/talk/trading-assistant/</link>
      <pubDate>Wed, 04 Mar 2020 15:30:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/talk/trading-assistant/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trading Assistant</title>
      <link>https://victorzxy.github.io/post/trading-assistant/</link>
      <pubDate>Mon, 02 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/trading-assistant/</guid>
      <description>&lt;p&gt;This is an web service written in Python and JavaScript, developed for &lt;a href=&#34;https://www.imc.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IMC Trading&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Not all trading happens on the exchanges—sometimes counterparties trade directly through human-to-human communication. In such cases, humans typically use their most natural interface: voice. The Trading Assistant holds market data and responds to queries on demand in a human-like manner, by automating the trader side of the trading communication using modern technologies, including speech recognition, natural language processing, and speech synthesis. The speech recognition and speech synthesis module of the Trading Assistant was built based on the Google Cloud Speech-to-Text and Text-to-Speech APIs. The Trading Assistant also adopts a Naïve Bayes approach for NLP, using word2vec for word embeddings and Siamese BERT for sentence embeddings.&lt;/p&gt;
&lt;p&gt;I was responsible for building the speech recognition and speech synthesis modules, and efficiently built the libraries with high accuracies, and provided clean interfaces that were used conveniently by my NLP and back-end teammates, improving the system&amp;rsquo;s overall performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trading Assistant</title>
      <link>https://victorzxy.github.io/project/trading-assistant/</link>
      <pubDate>Mon, 02 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/trading-assistant/</guid>
      <description>&lt;p&gt;This is an web service written in Python and JavaScript, developed for &lt;a href=&#34;https://www.imc.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IMC Trading&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Not all trading happens on the exchanges—sometimes counterparties trade directly through human-to-human communication. In such cases, humans typically use their most natural interface: voice. The Trading Assistant holds market data and responds to queries on demand in a human-like manner, by automating the trader side of the trading communication using modern technologies, including speech recognition, natural language processing, and speech synthesis. The speech recognition and speech synthesis module of the Trading Assistant was built based on the Google Cloud Speech-to-Text and Text-to-Speech APIs. The Trading Assistant also adopts a Naïve Bayes approach for NLP, using word2vec for word embeddings and Siamese BERT for sentence embeddings.&lt;/p&gt;
&lt;p&gt;I was responsible for building the speech recognition and speech synthesis modules, and efficiently built the libraries with high accuracies, and provided clean interfaces that were used conveniently by my NLP and back-end teammates, improving the system&amp;rsquo;s overall performance.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
