<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TensorFlow | Xiangyu Zhao</title>
    <link>https://victorzxy.github.io/tag/tensorflow/</link>
      <atom:link href="https://victorzxy.github.io/tag/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    <description>TensorFlow</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2022 Xiangyu Zhao</copyright><lastBuildDate>Fri, 25 Feb 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://victorzxy.github.io/media/icon_hu51ffffd5f6381cda320d0c97647d90a4_34098_512x512_fill_lanczos_center_3.png</url>
      <title>TensorFlow</title>
      <link>https://victorzxy.github.io/tag/tensorflow/</link>
    </image>
    
    <item>
      <title>Building a 3-Player Mahjong AI using Deep Reinforcement Learning</title>
      <link>https://victorzxy.github.io/publication/2022-meowjong/</link>
      <pubDate>Fri, 25 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/publication/2022-meowjong/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>A Neural Network Approach to Named Entity Recognition on Noisy User-Generated Texts</title>
      <link>https://victorzxy.github.io/post/nlp-final-assignment-ner/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/nlp-final-assignment-ner/</guid>
      <description>&lt;p&gt;Named entity recognition (NER) is an important information extraction task in natural language processing (NLP) which involves automatic identification of entities of interest, such as people&amp;rsquo;s names, organisations and locations. Current state-of-the-art NER systems can achieve F1-scores of up to 94.6% on English news texts (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.206.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021a&lt;/a&gt;), where the named entities are fairly standard, well-formed and highly predictable. However, the diverse and noisy nature of user-generated texts as well as the novel, emerging and rare named entities make NER in social media much more challenging, and standard NER sysmtes were not found to work very well on these tasks. As a comparison, current state-of-the-art NER systems on user-generated texts can only achieve F1-scores of up to 60.45% (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.142.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021b&lt;/a&gt;). In this project, I investigated a bidirectional long short-term memory (BiLSTM) structure for NER on social media texts, explored various data-processing techniques in order to improve the model&amp;rsquo;s performance, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downweighting non-named entity labels&lt;/li&gt;
&lt;li&gt;Downsampling non-named entity tokens&lt;/li&gt;
&lt;li&gt;Merging named entity labels&lt;/li&gt;
&lt;li&gt;Adding part-of-speech (PoS) embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then evaluated my trained models on the W-NUT 2017 shared task on novel and emerging entity recognition. The model trained with data-processing techniques applied has achieved significant improvements on performance, compared to the model with the same structure, but trained on the original dataset without any optimisation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Neural Network Approach to Named Entity Recognition on Noisy User-Generated Texts</title>
      <link>https://victorzxy.github.io/project/nlp-final-assignment-ner/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/nlp-final-assignment-ner/</guid>
      <description>&lt;p&gt;Named entity recognition (NER) is an important information extraction task in natural language processing (NLP) which involves automatic identification of entities of interest, such as people&amp;rsquo;s names, organisations and locations. Current state-of-the-art NER systems can achieve F1-scores of up to 94.6% on English news texts (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.206.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021a&lt;/a&gt;), where the named entities are fairly standard, well-formed and highly predictable. However, the diverse and noisy nature of user-generated texts as well as the novel, emerging and rare named entities make NER in social media much more challenging, and standard NER sysmtes were not found to work very well on these tasks. As a comparison, current state-of-the-art NER systems on user-generated texts can only achieve F1-scores of up to 60.45% (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.142.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021b&lt;/a&gt;). In this project, I investigated a bidirectional long short-term memory (BiLSTM) structure for NER on social media texts, explored various data-processing techniques in order to improve the model&amp;rsquo;s performance, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downweighting non-named entity labels&lt;/li&gt;
&lt;li&gt;Downsampling non-named entity tokens&lt;/li&gt;
&lt;li&gt;Merging named entity labels&lt;/li&gt;
&lt;li&gt;Adding part-of-speech (PoS) embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then evaluated my trained models on the W-NUT 2017 shared task on novel and emerging entity recognition. The model trained with data-processing techniques applied has achieved significant improvements on performance, compared to the model with the same structure, but trained on the original dataset without any optimisation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning for Mahjong</title>
      <link>https://victorzxy.github.io/post/meowjong/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/meowjong/</guid>
      <description>&lt;p&gt;Mahjong is a popular multi-player imperfect-information game developed in China in the late 19th-century, with some very challenging features for AI research. Sanma, being a 3-player variant of the Japanese Riichi Mahjong, possesses unique characteristics including fewer tiles and, consequently, a more aggressive playing style. It is thus challenging and of great research interest in its own right, but has not yet been explored. In this project, I built Meowjong, an AI for Sanma using deep reinforcement learning. I defined an informative and compact 2-dimensional data structure for encoding the observable information in a Sanma game. Then, I pre-trained 5 convolutional neural networks (CNNs) for Sanma&amp;rsquo;s 5 actions—discard, Pon, Kan, Kita and Riichi, and enhanced the major action&amp;rsquo;s model, namely the discard model, via self-play reinforcement learning using the Monte Carlo policy gradient method. I have also implemeted necessary additional modules including data collection and processing, Mahjong hand calculation and a game simulator, for the agents to be trained and evaluated. Meowjong&amp;rsquo;s models have achieved test accuracies comparable with AIs for 4-player Mahjong through supervised learning, and gained a significant further enhancement from reinforcement learning. Being the first ever AI in Sanma, Meowjong stands as a state-of-the-art in this game.&lt;/p&gt;
&lt;p&gt;A paper from this dissertation has been submitted to IEEE Conference on Games (IEEE CoG) 2022.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning for Mahjong</title>
      <link>https://victorzxy.github.io/project/meowjong/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/meowjong/</guid>
      <description>&lt;p&gt;Mahjong is a popular multi-player imperfect-information game developed in China in the late 19th-century, with some very challenging features for AI research. Sanma, being a 3-player variant of the Japanese Riichi Mahjong, possesses unique characteristics including fewer tiles and, consequently, a more aggressive playing style. It is thus challenging and of great research interest in its own right, but has not yet been explored. In this project, I built Meowjong, an AI for Sanma using deep reinforcement learning. I defined an informative and compact 2-dimensional data structure for encoding the observable information in a Sanma game. Then, I pre-trained 5 convolutional neural networks (CNNs) for Sanma&amp;rsquo;s 5 actions—discard, Pon, Kan, Kita and Riichi, and enhanced the major action&amp;rsquo;s model, namely the discard model, via self-play reinforcement learning using the Monte Carlo policy gradient method. I have also implemeted necessary additional modules including data collection and processing, Mahjong hand calculation and a game simulator, for the agents to be trained and evaluated. Meowjong&amp;rsquo;s models have achieved test accuracies comparable with AIs for 4-player Mahjong through supervised learning, and gained a significant further enhancement from reinforcement learning. Being the first ever AI in Sanma, Meowjong stands as a state-of-the-art in this game.&lt;/p&gt;
&lt;p&gt;A paper from this dissertation has been submitted to IEEE Conference on Games (IEEE CoG) 2022.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysing Clickstream Data for Online Shopping</title>
      <link>https://victorzxy.github.io/post/datasci-pnp-final-practical/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/datasci-pnp-final-practical/</guid>
      <description>&lt;p&gt;In this project, I analysed a clickstream dataset of an online shopping website for clothing between April and August 2008, and built a machine learning pipeline to predict the costumer’s potential willingness to pay a premium price. I explored, trained and compared various machine learning models for this task, ranging from traditional models to deep neural networks, and identified the most important features for predicting the target value. The best-performing model the I trained for this project has achieved a test accuracy of 93.37%. I also performed visualisation and dimensionality reduction, using PCA and t-SNE, to reveal properties of the dataset and my models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysing Clickstream Data for Online Shopping</title>
      <link>https://victorzxy.github.io/project/datasci-pnp-final-practical/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/datasci-pnp-final-practical/</guid>
      <description>&lt;p&gt;In this project, I analysed a clickstream dataset of an online shopping website for clothing between April and August 2008, and built a machine learning pipeline to predict the costumer’s potential willingness to pay a premium price. I explored, trained and compared various machine learning models for this task, ranging from traditional models to deep neural networks, and identified the most important features for predicting the target value. The best-performing model the I trained for this project has achieved a test accuracy of 93.37%. I also performed visualisation and dimensionality reduction, using PCA and t-SNE, to reveal properties of the dataset and my models.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
