<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Natural Language Processing | Xiangyu Zhao</title>
    <link>https://victorzxy.github.io/tag/natural-language-processing/</link>
      <atom:link href="https://victorzxy.github.io/tag/natural-language-processing/index.xml" rel="self" type="application/rss+xml" />
    <description>Natural Language Processing</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2022 Xiangyu Zhao</copyright><lastBuildDate>Fri, 03 Dec 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://victorzxy.github.io/media/icon_hu51ffffd5f6381cda320d0c97647d90a4_34098_512x512_fill_lanczos_center_3.png</url>
      <title>Natural Language Processing</title>
      <link>https://victorzxy.github.io/tag/natural-language-processing/</link>
    </image>
    
    <item>
      <title>A Neural Network Approach to Named Entity Recognition on Noisy User-Generated Texts</title>
      <link>https://victorzxy.github.io/post/nlp-final-assignment-ner/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/nlp-final-assignment-ner/</guid>
      <description>&lt;p&gt;Named entity recognition (NER) is an important information extraction task in natural language processing (NLP) which involves automatic identification of entities of interest, such as people&amp;rsquo;s names, organisations and locations. Current state-of-the-art NER systems can achieve F1-scores of up to 94.6% on English news texts (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.206.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021a&lt;/a&gt;), where the named entities are fairly standard, well-formed and highly predictable. However, the diverse and noisy nature of user-generated texts as well as the novel, emerging and rare named entities make NER in social media much more challenging, and standard NER sysmtes were not found to work very well on these tasks. As a comparison, current state-of-the-art NER systems on user-generated texts can only achieve F1-scores of up to 60.45% (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.142.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021b&lt;/a&gt;). In this project, I investigated a bidirectional long short-term memory (BiLSTM) structure for NER on social media texts, explored various data-processing techniques in order to improve the model&amp;rsquo;s performance, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downweighting non-named entity labels&lt;/li&gt;
&lt;li&gt;Downsampling non-named entity tokens&lt;/li&gt;
&lt;li&gt;Merging named entity labels&lt;/li&gt;
&lt;li&gt;Adding part-of-speech (PoS) embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then evaluated my trained models on the W-NUT 2017 shared task on novel and emerging entity recognition. The model trained with data-processing techniques applied has achieved significant improvements on performance, compared to the model with the same structure, but trained on the original dataset without any optimisation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Neural Network Approach to Named Entity Recognition on Noisy User-Generated Texts</title>
      <link>https://victorzxy.github.io/project/nlp-final-assignment-ner/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/nlp-final-assignment-ner/</guid>
      <description>&lt;p&gt;Named entity recognition (NER) is an important information extraction task in natural language processing (NLP) which involves automatic identification of entities of interest, such as people&amp;rsquo;s names, organisations and locations. Current state-of-the-art NER systems can achieve F1-scores of up to 94.6% on English news texts (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.206.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021a&lt;/a&gt;), where the named entities are fairly standard, well-formed and highly predictable. However, the diverse and noisy nature of user-generated texts as well as the novel, emerging and rare named entities make NER in social media much more challenging, and standard NER sysmtes were not found to work very well on these tasks. As a comparison, current state-of-the-art NER systems on user-generated texts can only achieve F1-scores of up to 60.45% (&lt;a href=&#34;https://aclanthology.org/2021.acl-long.142.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wang &lt;em&gt;et al.&lt;/em&gt;, 2021b&lt;/a&gt;). In this project, I investigated a bidirectional long short-term memory (BiLSTM) structure for NER on social media texts, explored various data-processing techniques in order to improve the model&amp;rsquo;s performance, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downweighting non-named entity labels&lt;/li&gt;
&lt;li&gt;Downsampling non-named entity tokens&lt;/li&gt;
&lt;li&gt;Merging named entity labels&lt;/li&gt;
&lt;li&gt;Adding part-of-speech (PoS) embeddings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then evaluated my trained models on the W-NUT 2017 shared task on novel and emerging entity recognition. The model trained with data-processing techniques applied has achieved significant improvements on performance, compared to the model with the same structure, but trained on the original dataset without any optimisation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trading Assistant</title>
      <link>https://victorzxy.github.io/talk/trading-assistant/</link>
      <pubDate>Wed, 04 Mar 2020 15:30:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/talk/trading-assistant/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trading Assistant</title>
      <link>https://victorzxy.github.io/post/trading-assistant/</link>
      <pubDate>Mon, 02 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/trading-assistant/</guid>
      <description>&lt;p&gt;This is an web service written in Python and JavaScript, developed for &lt;a href=&#34;https://www.imc.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IMC Trading&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Not all trading happens on the exchanges—sometimes counterparties trade directly through human-to-human communication. In such cases, humans typically use their most natural interface: voice. The Trading Assistant holds market data and responds to queries on demand in a human-like manner, by automating the trader side of the trading communication using modern technologies, including speech recognition, natural language processing, and speech synthesis. The speech recognition and speech synthesis module of the Trading Assistant was built based on the Google Cloud Speech-to-Text and Text-to-Speech APIs. The Trading Assistant also adopts a Naïve Bayes approach for NLP, using word2vec for word embeddings and Siamese BERT for sentence embeddings.&lt;/p&gt;
&lt;p&gt;I was responsible for building the speech recognition and speech synthesis modules, and efficiently built the libraries with high accuracies, and provided clean interfaces that were used conveniently by my NLP and back-end teammates, improving the system&amp;rsquo;s overall performance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trading Assistant</title>
      <link>https://victorzxy.github.io/project/trading-assistant/</link>
      <pubDate>Mon, 02 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/trading-assistant/</guid>
      <description>&lt;p&gt;This is an web service written in Python and JavaScript, developed for &lt;a href=&#34;https://www.imc.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IMC Trading&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Not all trading happens on the exchanges—sometimes counterparties trade directly through human-to-human communication. In such cases, humans typically use their most natural interface: voice. The Trading Assistant holds market data and responds to queries on demand in a human-like manner, by automating the trader side of the trading communication using modern technologies, including speech recognition, natural language processing, and speech synthesis. The speech recognition and speech synthesis module of the Trading Assistant was built based on the Google Cloud Speech-to-Text and Text-to-Speech APIs. The Trading Assistant also adopts a Naïve Bayes approach for NLP, using word2vec for word embeddings and Siamese BERT for sentence embeddings.&lt;/p&gt;
&lt;p&gt;I was responsible for building the speech recognition and speech synthesis modules, and efficiently built the libraries with high accuracies, and provided clean interfaces that were used conveniently by my NLP and back-end teammates, improving the system&amp;rsquo;s overall performance.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
