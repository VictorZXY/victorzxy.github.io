<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PyTorch | Xiangyu Zhao</title>
    <link>https://victorzxy.github.io/tag/pytorch/</link>
      <atom:link href="https://victorzxy.github.io/tag/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <description>PyTorch</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2022 Xiangyu Zhao</copyright><lastBuildDate>Mon, 21 Aug 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://victorzxy.github.io/media/icon_hu445124fc86f9a5e0ef5204885c05fa2c_2309_512x512_fill_lanczos_center_3.png</url>
      <title>PyTorch</title>
      <link>https://victorzxy.github.io/tag/pytorch/</link>
    </image>
    
    <item>
      <title>Investigating GNN Expressiveness in Graph Generation Tasks</title>
      <link>https://victorzxy.github.io/post/expressive-graph-gen-extend/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/expressive-graph-gen-extend/</guid>
      <description>&lt;p&gt;Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZINC-250k dataset. Through our extensive experiments, we demonstrate that advanced GNNs can indeed improve the performance of GCPN and GraphAF on molecular generation tasks, but GNN expressiveness is not a necessary condition for a good GNN-based generative model. Moreover, we show that GCPN and GraphAF with advanced GNNs can achieve state-of-the-art results across 17 other non-GNN-based graph generative approaches, such as variational autoencoders and Bayesian optimisation models, on the proposed molecular generative objectives (DRD2, Median1, Median2), which are important metrics for de-novo molecular design.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigating GNN Expressiveness in Graph Generation Tasks</title>
      <link>https://victorzxy.github.io/project/expressive-graph-gen-extend/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/expressive-graph-gen-extend/</guid>
      <description>&lt;p&gt;Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZINC-250k dataset. Through our extensive experiments, we demonstrate that advanced GNNs can indeed improve the performance of GCPN and GraphAF on molecular generation tasks, but GNN expressiveness is not a necessary condition for a good GNN-based generative model. Moreover, we show that GCPN and GraphAF with advanced GNNs can achieve state-of-the-art results across 17 other non-GNN-based graph generative approaches, such as variational autoencoders and Bayesian optimisation models, on the proposed molecular generative objectives (DRD2, Median1, Median2), which are important metrics for de-novo molecular design.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Will More Expressive Graph Neural Networks do Better on Generative Tasks?</title>
      <link>https://victorzxy.github.io/publication/2023-expressive-graph-gen-extend/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/publication/2023-expressive-graph-gen-extend/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Hybrid Graph: A Unified Graph Representation with Datasets and Benchmarks for Complex Graphs</title>
      <link>https://victorzxy.github.io/publication/2023-hybrid-graph-benchmark/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/publication/2023-hybrid-graph-benchmark/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Unifying Higher-Order Graph Representation with New Datasets and Benchmarks</title>
      <link>https://victorzxy.github.io/post/hybrid-graph-benchmark/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/hybrid-graph-benchmark/</guid>
      <description>&lt;p&gt;Graphs are widely used to encapsulate a variety of data formats, but real-world networks often involve complex node relations beyond only being pairwise. While hypergraphs and hierarchical graphs have been developed and employed to account for the complex node relations, they cannot fully represent these complexities in practice. Additionally, though many Graph Neural Networks (GNNs) have been proposed for representation learning on higher-order graphs, they are usually only evaluated on simple graph datasets. Therefore, there is a need for a unified modelling of higher-order graphs, and a collection of comprehensive datasets with an accessible evaluation framework to fully understand the performance of these algorithms on complex graphs. In this paper, we introduce the concept of hybrid graphs, a unified definition for higher-order graphs, and present the Hybrid Graph Benchmark (HGB). HGB contains 23 real-world hybrid graph datasets across various domains such as biology, social media, and e-commerce. Furthermore, we provide an extensible evaluation framework and a supporting codebase to facilitate the training and evaluation of GNNs on HGB. Our empirical study of existing GNNs on HGB reveals various research opportunities and gaps, including (1) evaluating the actual performance improvement of hypergraph GNNs over simple graph GNNs; (2) comparing the impact of different sampling strategies on hybrid graph learning methods; and (3) exploring ways to integrate simple graph and hypergraph information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unifying Higher-Order Graph Representation with New Datasets and Benchmarks</title>
      <link>https://victorzxy.github.io/project/hybrid-graph-benchmark/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/hybrid-graph-benchmark/</guid>
      <description>&lt;p&gt;Graphs are widely used to encapsulate a variety of data formats, but real-world networks often involve complex node relations beyond only being pairwise. While hypergraphs and hierarchical graphs have been developed and employed to account for the complex node relations, they cannot fully represent these complexities in practice. Additionally, though many Graph Neural Networks (GNNs) have been proposed for representation learning on higher-order graphs, they are usually only evaluated on simple graph datasets. Therefore, there is a need for a unified modelling of higher-order graphs, and a collection of comprehensive datasets with an accessible evaluation framework to fully understand the performance of these algorithms on complex graphs. In this paper, we introduce the concept of hybrid graphs, a unified definition for higher-order graphs, and present the Hybrid Graph Benchmark (HGB). HGB contains 23 real-world hybrid graph datasets across various domains such as biology, social media, and e-commerce. Furthermore, we provide an extensible evaluation framework and a supporting codebase to facilitate the training and evaluation of GNNs on HGB. Our empirical study of existing GNNs on HGB reveals various research opportunities and gaps, including (1) evaluating the actual performance improvement of hypergraph GNNs over simple graph GNNs; (2) comparing the impact of different sampling strategies on hybrid graph learning methods; and (3) exploring ways to integrate simple graph and hypergraph information.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration</title>
      <link>https://victorzxy.github.io/publication/2023-graphac/</link>
      <pubDate>Fri, 27 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/publication/2023-graphac/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration</title>
      <link>https://victorzxy.github.io/talk/task-agnostic-graph-neural-network-evaluation-via-adversarial-collaboration/</link>
      <pubDate>Wed, 08 Jun 2022 09:10:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/talk/task-agnostic-graph-neural-network-evaluation-via-adversarial-collaboration/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration</title>
      <link>https://victorzxy.github.io/post/graphac/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/post/graphac/</guid>
      <description>&lt;p&gt;Graph Neural Networks (GNNs) have experienced rapid growth over the last decade, and have been successful in many real-world applications. In order to cope with the rapid growth of this field, it is increasingly demanding to develop reliable GNN evaluation methods to facilitate GNN research and quantify their progress. Current GNN benchmarking methods all focus on comparing the GNNs with respect to their training performances on some node/graph classification/regression tasks in certain datasets, but there has not been any principled, task-agnostic method to directly compare the two GNNs.&lt;/p&gt;
&lt;p&gt;Furthermore, learning informative representations of graph-structured data using self-supervised learning (SSL) is becoming crucial in many real-world tasks nowadays, when labelled data are expensive and limited. Most of the existing graph SSL works incorporate handcrafted augmentations to the graph, which has several severe difficulties due to the unique characteristics of graph-structured data. Therefore, it is highly needed to develop a principled SSL framework across various types of graphs, that does not require handcrafted augmentations.&lt;/p&gt;
&lt;p&gt;In this project, I tackled both questions above, and developed GraphAC (Graph Adversarial Collaboration), a conceptually novel, principled, task-agnostic, and stable framework for evaluating GNNs through contrastive self-supervision. It consists of two different GNNs directly competing against each other, with the more expressive GNN wins by producing more informative graph representations. I built two frameworks for GraphAC, and designed a novel objective function that enables stable and effective training of two different GNNs, inspired by Barlow Twins.&lt;/p&gt;
&lt;p&gt;The experimental results show that GraphAC succeeds in distinguishing GNNs of different expressivity across various aspects including the number of layers, hidden dimensionality, aggregators, GNN architecture and edge features, and always allow more expressive GNNs to win with statistically significant difference. GraphAC proved to be a principled and reliable GNN evaluation method, and enables stable SSL without needing handcrafted augmentations.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;https://victorzxy.github.io/publication/2023-graphac&#34;&gt;paper&lt;/a&gt; from this dissertation is accepted at the ICLR 2023 Machine Learning for Drug Discovery (MLDD) Workshop.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration</title>
      <link>https://victorzxy.github.io/project/graphac/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/graphac/</guid>
      <description>&lt;p&gt;Graph Neural Networks (GNNs) have experienced rapid growth over the last decade, and have been successful in many real-world applications. In order to cope with the rapid growth of this field, it is increasingly demanding to develop reliable GNN evaluation methods to facilitate GNN research and quantify their progress. Current GNN benchmarking methods all focus on comparing the GNNs with respect to their training performances on some node/graph classification/regression tasks in certain datasets, but there has not been any principled, task-agnostic method to directly compare the two GNNs.&lt;/p&gt;
&lt;p&gt;Furthermore, learning informative representations of graph-structured data using self-supervised learning (SSL) is becoming crucial in many real-world tasks nowadays, when labelled data are expensive and limited. Most of the existing graph SSL works incorporate handcrafted augmentations to the graph, which has several severe difficulties due to the unique characteristics of graph-structured data. Therefore, it is highly needed to develop a principled SSL framework across various types of graphs, that does not require handcrafted augmentations.&lt;/p&gt;
&lt;p&gt;In this project, I tackled both questions above, and developed GraphAC (Graph Adversarial Collaboration), a conceptually novel, principled, task-agnostic, and stable framework for evaluating GNNs through contrastive self-supervision. It consists of two different GNNs directly competing against each other, with the more expressive GNN wins by producing more informative graph representations. I built two frameworks for GraphAC, and designed a novel objective function that enables stable and effective training of two different GNNs, inspired by Barlow Twins.&lt;/p&gt;
&lt;p&gt;The experimental results show that GraphAC succeeds in distinguishing GNNs of different expressivity across various aspects including the number of layers, hidden dimensionality, aggregators, GNN architecture and edge features, and always allow more expressive GNNs to win with statistically significant difference. GraphAC proved to be a principled and reliable GNN evaluation method, and enables stable SSL without needing handcrafted augmentations.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;https://victorzxy.github.io/publication/2023-graphac&#34;&gt;paper&lt;/a&gt; from this dissertation is accepted at the ICLR 2023 Machine Learning for Drug Discovery (MLDD) Workshop.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Graph Generative Models via Expressive Graph Neural Networks</title>
      <link>https://victorzxy.github.io/archive/expressive-graph-gen/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/archive/expressive-graph-gen/</guid>
      <description>&lt;p&gt;Graph generation is a very challenging problem that requires predicting an entire graph with multiple nodes and edges from a given label, and is fundamental for many real-world tasks, such as molecular graph generation for drug discovery. A lot of successful methods have been explored on graph generation, including Graph Convolutional Policy Network (GCPN) and GraphAF, but the underlying graph neural network (GNN) structure for graph representation within both works remains untouched, namely the Relational Graph Convolutional Network (R-GCN). In this project, we investigate the expressivity of GNNs under the context of the graph generation problem, by replacing R-GCN in GCPN with more expressive GNNs, including Graph Isomorphism Network (GIN), Principal Neighbourhood Aggregation (PNA) and Graph Substructure Network (GSN). Experimental results show that more expressive GNNs can indeed significantly improve GCPN&amp;rsquo;s performance on chemical property optimisation, with the only bottleneck coming from the sensitive nature of the graph generative method. In addition, since nearly all of the recent works on new GNN architectures are focused on pushing node/graph classification/regression benchmarks, which are comparatively simpler than graph generation modelling in terms of the combinatorial complexity, we also wish to challenge the graph representation learning community&amp;rsquo;s notion for benchmarking the expressivity of GNNs with this project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Graph Generative Models via Expressive Graph Neural Networks</title>
      <link>https://victorzxy.github.io/project/expressive-graph-gen/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/expressive-graph-gen/</guid>
      <description>&lt;p&gt;Graph generation is a very challenging problem that requires predicting an entire graph with multiple nodes and edges from a given label, and is fundamental for many real-world tasks, such as molecular graph generation for drug discovery. A lot of successful methods have been explored on graph generation, including Graph Convolutional Policy Network (GCPN) and GraphAF, but the underlying graph neural network (GNN) structure for graph representation within both works remains untouched, namely the Relational Graph Convolutional Network (R-GCN). In this project, we investigate the expressivity of GNNs under the context of the graph generation problem, by replacing R-GCN in GCPN with more expressive GNNs, including Graph Isomorphism Network (GIN), Principal Neighbourhood Aggregation (PNA) and Graph Substructure Network (GSN). Experimental results show that more expressive GNNs can indeed significantly improve GCPN&amp;rsquo;s performance on chemical property optimisation, with the only bottleneck coming from the sensitive nature of the graph generative method. In addition, since nearly all of the recent works on new GNN architectures are focused on pushing node/graph classification/regression benchmarks, which are comparatively simpler than graph generation modelling in terms of the combinatorial complexity, we also wish to challenge the graph representation learning community&amp;rsquo;s notion for benchmarking the expressivity of GNNs with this project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Agent Deep Q-Learning for the Berry Poisoning Game</title>
      <link>https://victorzxy.github.io/archive/dqn-berry-poisoning/</link>
      <pubDate>Thu, 17 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/archive/dqn-berry-poisoning/</guid>
      <description>&lt;p&gt;Deep Q-learning (DQN) is a successful algorithm that combines deep learning with reinforcement learning. However, it is of great research interest whether this method can work in a multi-agent environment. In this mini-project, I performed a multi-agent DQN method on the Berry Poisoning Games, and investigated on the agent performance with respect to different game environment parameters, including the bad berry rate, bad/good berry reward ratio, number of agents, and agent visibility range. The results clearly show that my DQN method can successfully train agents to act sensibly in such an environment, within only a few episodes of training. My DQN method also succeeds in transfer learning, training agents that still perform well in other game environment setups, and can be further enhanced through fine-tuning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Agent Deep Q-Learning for the Berry Poisoning Game</title>
      <link>https://victorzxy.github.io/project/dqn-berry-poisoning/</link>
      <pubDate>Thu, 17 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/dqn-berry-poisoning/</guid>
      <description>&lt;p&gt;Deep Q-learning (DQN) is a successful algorithm that combines deep learning with reinforcement learning. However, it is of great research interest whether this method can work in a multi-agent environment. In this mini-project, I performed a multi-agent DQN method on the Berry Poisoning Games, and investigated on the agent performance with respect to different game environment parameters, including the bad berry rate, bad/good berry reward ratio, number of agents, and agent visibility range. The results clearly show that my DQN method can successfully train agents to act sensibly in such an environment, within only a few episodes of training. My DQN method also succeeds in transfer learning, training agents that still perform well in other game environment setups, and can be further enhanced through fine-tuning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Function Autoencoders: A Neural Network Approach to Gaussian Processes</title>
      <link>https://victorzxy.github.io/archive/function-autoencoders/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/archive/function-autoencoders/</guid>
      <description>&lt;p&gt;Gaussian processes (GPs) are data-efficient and flexible probabilistic methods that learn distributions of functions based on given priors. However, GPs suffer from unscalability as they become very computationally expensive on large datasets, and choosing the appropriate priors for GPs can be nontrivial. In this project, I investigated a neural network (NN) alternative to GPs, and introduced the function autoencoders that preserve GPsâ own advantages and avoid their weaknesses with NNsâ benefits. I tested the performance of the various function autoencoders on a 1-dimensional function regression task, using random functions generated by a GP with varying kernel parameters, and compared and analysed their results. The trained function autoencoder models indeed have the ability to learn distributions over random functions, and performed decently on the selected task. Moreover, the function autoencoders demonstrate a great potential for further improvements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Function Autoencoders: A Neural Network Approach to Gaussian Processes</title>
      <link>https://victorzxy.github.io/project/function-autoencoders/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/function-autoencoders/</guid>
      <description>&lt;p&gt;Gaussian processes (GPs) are data-efficient and flexible probabilistic methods that learn distributions of functions based on given priors. However, GPs suffer from unscalability as they become very computationally expensive on large datasets, and choosing the appropriate priors for GPs can be nontrivial. In this project, I investigated a neural network (NN) alternative to GPs, and introduced the function autoencoders that preserve GPsâ own advantages and avoid their weaknesses with NNsâ benefits. I tested the performance of the various function autoencoders on a 1-dimensional function regression task, using random functions generated by a GP with varying kernel parameters, and compared and analysed their results. The trained function autoencoder models indeed have the ability to learn distributions over random functions, and performed decently on the selected task. Moreover, the function autoencoders demonstrate a great potential for further improvements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Investigating Adversarial Examples for Deep Residual Networks</title>
      <link>https://victorzxy.github.io/archive/fgsm-attack-resnets/</link>
      <pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/archive/fgsm-attack-resnets/</guid>
      <description>&lt;p&gt;In this project, I investigated the one-shot and iterative fast gradient sign method (FGSM) attack, both untargeted and targeted, to generate adversarial examples for ResNet-50, and experimented the transferability of each FGSM to other neural networks, namely ResNet-18 and VGG-19, as well as other image inputs. The following conclusions can be reached after the above experiments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Targeted FGSM is more effective than FGSM;&lt;/li&gt;
&lt;li&gt;In white-box attacks, both the untargeted and targeted one-shot FGSMs are less effective than the iterative methods (both untargeted and targeted);&lt;/li&gt;
&lt;li&gt;When it comes to transferability to other neural networks or inputs, the one-shot FGSMs turn out to be much more effective than the iterative FGSMs, as the iterative FGSMs suffer from overfitting and hence completely unable to transfer to other neural networks or inputs.&lt;/li&gt;
&lt;li&gt;Since transferability is a foundation to black-box attacks, it is likely that the one-shot FGSMs can also be more effective than the iterative FGSMs in black-box attacks.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Investigating Adversarial Examples for Deep Residual Networks</title>
      <link>https://victorzxy.github.io/project/fgsm-attack-resnets/</link>
      <pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://victorzxy.github.io/project/fgsm-attack-resnets/</guid>
      <description>&lt;p&gt;In this project, I investigated the one-shot and iterative fast gradient sign method (FGSM) attack, both untargeted and targeted, to generate adversarial examples for ResNet-50, and experimented the transferability of each FGSM to other neural networks, namely ResNet-18 and VGG-19, as well as other image inputs. The following conclusions can be reached after the above experiments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Targeted FGSM is more effective than FGSM;&lt;/li&gt;
&lt;li&gt;In white-box attacks, both the untargeted and targeted one-shot FGSMs are less effective than the iterative methods (both untargeted and targeted);&lt;/li&gt;
&lt;li&gt;When it comes to transferability to other neural networks or inputs, the one-shot FGSMs turn out to be much more effective than the iterative FGSMs, as the iterative FGSMs suffer from overfitting and hence completely unable to transfer to other neural networks or inputs.&lt;/li&gt;
&lt;li&gt;Since transferability is a foundation to black-box attacks, it is likely that the one-shot FGSMs can also be more effective than the iterative FGSMs in black-box attacks.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
